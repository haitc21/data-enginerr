1.Transform the data structure
- Filtering rows and columns
- Renaming columns
- Creating new columns, often derived from existing ones
- Replaci- ng null or other values
Example: uses the split function to separate the values in the CustomerName column into two new columns named FirstName and LastName

from pyspark.sql.functions import split, col

# Create the new FirstName and LastName fields
transformed_df = order_details.withColumn("FirstName", split(col("CustomerName"), " ").getItem(0)).withColumn("LastName", split(col("CustomerName"), " ").getItem(1))

# Remove the CustomerName field
transformed_df = transformed_df.drop("CustomerName")

display(transformed_df.limit(5))

2. Save the transformed data

transformed_df.write.mode("overwrite").parquet('/transformed_data/orders.parquet')
print ("Transformed data saved!")

3. Partition data files

from pyspark.sql.functions import year, col

# Load source data
df = spark.read.csv('/orders/*.csv', header=True, inferSchema=True)

# Add Year column
dated_df = df.withColumn("Year", year(col("OrderDate")))

# Partition by year
dated_df.write.partitionBy("Year").mode("overwrite").parquet("/data")

Result: /data: Year=2021 Year=2022

orders_2020 = spark.read.parquet('/partitioned_data/Year=2020')
display(orders_2020.limit(5))

4. Define tables and views
Table definitions in Spark are stored in the metastore, a metadata layer that encapsulates relational abstractions over files.

order_details.write.saveAsTable('sales_orders', format='parquet', mode='overwrite', path='/sales_orders_table')

- Use SQL to query and transform the data


# Create derived columns
sql_transform = spark.sql("SELECT *, YEAR(OrderDate) AS Year, MONTH(OrderDate) AS Month FROM sales_orders")

# Save the results
sql_transform.write.partitionBy("Year","Month").saveAsTable('transformed_orders', format='parquet', mode='overwrite', path='/transformed_orders_table')

- Query the metastore

%%sql

SELECT * FROM transformed_orders
WHERE Year = 2021
    AND Month = 1

- Drop tables
When working with external tables, you can use the DROP command to delete the table definitions from the metastore without affecting the files in the data lake.

%%sql

DROP TABLE transformed_orders;
DROP TABLE sales_orders;

